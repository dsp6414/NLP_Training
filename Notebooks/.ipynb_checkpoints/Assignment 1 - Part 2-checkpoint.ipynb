{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../word-embeddings-benchmark')\n",
    "\n",
    "from web.datasets.similarity import fetch_MTurk, fetch_WS353, fetch_RG65, fetch_RW\n",
    "from web.datasets.analogy import fetch_google_analogy\n",
    "\n",
    "#Important for converting embeddings to managable format\n",
    "from web.embedding import Embedding\n",
    "from web.embeddings import fetch_HPCA\n",
    "from web.evaluate import evaluate_similarity, evaluate_analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "All embeddings are used without normalization\n",
    "\n",
    "### GloVe:\n",
    "400,000 words, 6B tokens with 50, 100, 200, 300 dimensions\n",
    "\n",
    "### Fast Text\n",
    "wiki-news 16B tokens with 300 dimensions\n",
    "\n",
    "### LexVec\n",
    "Note: LexVec Common Crawl 58B tokens , 300 dimensions was 5GB. Hence uable to load onto memory\n",
    "Word + Context Vectors, 7B tokens, 300 dimensions\n",
    "\n",
    "### ConceptNet Number batch\n",
    "_ tokens, 300 dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We ignored line number 400000 because of errors in parsing\n",
      "index 400000 is out of bounds for axis 0 with size 400000\n"
     ]
    }
   ],
   "source": [
    "#Load time is about 5-10 mins\n",
    "glove = Embedding.from_glove('../Data/Embeddings/GloVe/glove.6B.300d.txt', 400000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load time is about 10-15 mins\n",
    "fast_text = Embedding.from_word2vec('../Data/Embeddings/FastText/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load time is about 10 mins\n",
    "lex_vec = Embedding.from_word2vec('../Data/Embeddings/LexVec/lexvec.enwiki+newscrawl.300d.W+C.pos.vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_net = Embedding.from_word2vec('../Data/Embeddings/ConceptNet/numberbatch-en.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Embedding  | Dim  |  MTurk |\n",
    "| ---------- | ---- | ------ |\n",
    "| Glove      |      |        |\n",
    "| Glove      |      |        |\n",
    "| FastText   | 300  | 0.7022 |\n",
    "| LexVec     | 300  | 0.6480 |\n",
    "| ConceptNet | 300  | 0.7188 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(file):\n",
    "    return pd.read_csv(file, header=None, sep=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTurk\n",
    "mturk = read_txt('../Data/Similarity/EN-TRUK.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mturk.iloc[:,:2].values\n",
    "y = mturk.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7188101234342916"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_similarity(concept_net, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Analogy\n",
    "\n",
    "Experiments (In terms of overall accuracy on all categories):<br/>\n",
    "Per parameter results are presented as tuples of (Overall accuracy %, number of corrects, total number of words) <br/>\n",
    "Results are provided with add rather than mul <br/>\n",
    "<br/>\n",
    "\n",
    "<b>GloVe:</b> <br/> \n",
    "<i>(Evaluation time: 15 mins on average)</i> <br/>\n",
    "* 300d : 65%, 12723, 19544\n",
    "* 200d : 60.8%, 11894, 19544\n",
    "* 100d : 49.7% , 9730, 19544\n",
    "* 50d  : 20.4%, 3997, 19544 \n",
    "\n",
    "<b>FastText:</b> <br/>\n",
    "<i>(Evaluation time: 20 mins)</i> <br/>\n",
    "* 300d : 9.2%, 1815, 19544\n",
    "\n",
    "<b>LexVec </b>\n",
    "* 300d : 60.4%, 11805, 19544\n",
    "\n",
    "<b> ConceptNet </b>\n",
    "* 300d : 31.9%, 6242, 19544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_analogy = fetch_google_analogy('../Data/Analogy/EN-GOOGLE.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_analogy(concept_net, google_analogy['X'], google_analogy['y'], category=google_analogy['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.319382</td>\n",
       "      <td>6242</td>\n",
       "      <td>19544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>0.116935</td>\n",
       "      <td>116</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>0.162162</td>\n",
       "      <td>216</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>0.158087</td>\n",
       "      <td>390</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>0.554054</td>\n",
       "      <td>738</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>0.291026</td>\n",
       "      <td>454</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>0.096059</td>\n",
       "      <td>78</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>0.680036</td>\n",
       "      <td>763</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>0.242424</td>\n",
       "      <td>256</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>0.537211</td>\n",
       "      <td>859</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0.128176</td>\n",
       "      <td>111</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>0.243678</td>\n",
       "      <td>212</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>0.388815</td>\n",
       "      <td>1759</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.310277</td>\n",
       "      <td>157</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>0.262846</td>\n",
       "      <td>133</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  correct  count\n",
       "all                          0.319382     6242  19544\n",
       "gram1-adjective-to-adverb    0.116935      116    992\n",
       "gram8-plural                 0.162162      216   1332\n",
       "city-in-state                0.158087      390   2467\n",
       "gram3-comparative            0.554054      738   1332\n",
       "gram7-past-tense             0.291026      454   1560\n",
       "gram2-opposite               0.096059       78    812\n",
       "gram4-superlative            0.680036      763   1122\n",
       "gram5-present-participle     0.242424      256   1056\n",
       "gram6-nationality-adjective  0.537211      859   1599\n",
       "currency                     0.128176      111    866\n",
       "gram9-plural-verbs           0.243678      212    870\n",
       "capital-world                0.388815     1759   4524\n",
       "family                       0.310277      157    506\n",
       "capital-common-countries     0.262846      133    506"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of similarity datasets to be evaluated:\n",
    "MTurk, MEN, WS353, Rubenstein and Goodenough, Rare Words, SimLex999, TR9856 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just downloading the files to compare and ensure I have the right datasets\n",
    "\n",
    "\n",
    "# dataset = fetch_MTurk()  #Downloaded. Yet to be understood\n",
    "# dataset = fetch_MEN()   #Not Downloaded\n",
    "# dataset = fetch_WS353(\"relatedness\") #Downloaded. Difference between relatedness and attributional\n",
    "# dataset = fetch_RG65() #Downloaded : Evaluate\n",
    "# dataset = fetch_RW() #Downloaded : Downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([['squishing', 'squirt'],\n",
       "        ['undated', 'undatable'],\n",
       "        ['circumvents', 'beat'],\n",
       "        ...,\n",
       "        ['irredeemable', 'wicked'],\n",
       "        ['irredeemable', 'inconvertible'],\n",
       "        ['snickering', 'laugh']], dtype=object),\n",
       " 'y': array([5.88, 5.83, 5.33, ..., 6.43, 6.57, 7.71]),\n",
       " 'sd': nan}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
