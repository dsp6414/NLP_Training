{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../word-embeddings-benchmark')\n",
    "\n",
    "from web.datasets.similarity import fetch_MTurk, fetch_MEN, fetch_WS353, fetch_RG65, fetch_RW, fetch_SimLex999, fetch_TR9856\n",
    "from web.datasets.analogy import fetch_google_analogy, fetch_msr_analogy, fetch_wordrep\n",
    "\n",
    "#Important for converting embeddings to managable format\n",
    "from web.embedding import Embedding\n",
    "from web.embeddings import fetch_HPCA\n",
    "from web.evaluate import evaluate_similarity, evaluate_analogy, evaluate_on_WordRep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "All embeddings are used without normalization\n",
    "\n",
    "### GloVe:\n",
    "400,000 words, 6B tokens with 50, 100, 200, 300 dimensions\n",
    "\n",
    "### Fast Text\n",
    "wiki-news 16B tokens with 300 dimensions\n",
    "\n",
    "### LexVec\n",
    "Note: LexVec Common Crawl 58B tokens , 300 dimensions was 5GB. Hence uable to load onto memory\n",
    "Word + Context Vectors, 7B tokens, 300 dimensions\n",
    "\n",
    "### ConceptNet Number batch\n",
    "_ tokens, 300 dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We ignored line number 400000 because of errors in parsing\n",
      "index 400000 is out of bounds for axis 0 with size 400000\n"
     ]
    }
   ],
   "source": [
    "#Load time is about 5-10 mins\n",
    "glove = Embedding.from_glove('../Data/Embeddings/GloVe/glove.6B.300d.txt', 400000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load time is about 10-15 mins\n",
    "fast_text = Embedding.from_word2vec('../Data/Embeddings/FastText/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load time is about 10 mins\n",
    "lex_vec = Embedding.from_word2vec('../Data/Embeddings/LexVec/lexvec.enwiki+newscrawl.300d.W+C.pos.vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load time is about 10 mins\n",
    "concept_net = Embedding.from_word2vec('../Data/Embeddings/ConceptNet/numberbatch-en.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google news\n",
    "google_news = Embedding.from_word2vec('../Data/Embeddings/GoogleNews/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDC\n",
    "pdc = Embedding.from_word2vec('../Data/Embeddings/PDC/wikicorp.201004-pdc-iter-20-alpha-0.05-window-10-dim-300-neg-10-subsample-0.0001.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HDC\n",
    "hdc = Embedding.from_word2vec('../Data/Embeddings/HDC/wikicorp.201004-hdc-iter-20-alpha-0.025-window-10-dim-300-neg-10-subsample-0.0001.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MTurk <br/>\n",
    "Evaluated by 10 people on a scale of  1 - 5. Scores are multipled by 2\n",
    "\n",
    "MEN <br/>\n",
    "Pairs: 3000\n",
    "Scores range : \n",
    "Natural form not lemmatized form. Scores were rescaled to stay within 0 - 10 range\n",
    "\n",
    "WS353 <br/>\n",
    "Pairs: 353\n",
    "Scores range : 0 - 10\n",
    "\n",
    "RG65 <br/>\n",
    "Pairs: 65\n",
    "Scores range : 0 - 4. Scaled by factor 10/4\n",
    "\n",
    "Rare Words <br/>\n",
    "Pairs: 2034\n",
    "Scores range : 0 - 10\n",
    "\n",
    "SimLex 999 <br/>\n",
    "Pairs: 999\n",
    "Scores range : 0 - 10\n",
    "\n",
    "TR9856 <br/>\n",
    "Pairs: 9856\n",
    "Scores range : 0 - 1\n",
    "\n",
    "\n",
    "| Embedding  | Dim  |  MTurk |  MEN  | WS353 | RG65 |  RW  | Sim999 |  TR9856  |  \n",
    "| ---------- | ---- | ------ |\n",
    "| Glove      |      |        |\n",
    "| Glove      |      |        |\n",
    "| FastText   | 300  | 0.7022 |\n",
    "| LexVec     | 300  | 0.6480 |\n",
    "| ConceptNet | 300  | 0.7188 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Similiarty datasets\n",
    "mturk = fetch_MTurk('../Data/Similarity/EN-TRUK.txt')\n",
    "men = fetch_MEN('../Data/Similarity/EN-MEN-LEM.txt')\n",
    "ws353 = fetch_WS353('../Data/Similarity/WS353_combined.csv')\n",
    "rg65 = fetch_RG65('../Data/Similarity/EN-RG-65.txt')\n",
    "rw = fetch_RW('../Data/Similarity/RW.txt')\n",
    "simlex = fetch_SimLex999('../Data/Similarity/EN-SIM999.txt')\n",
    "tr9856 = fetch_TR9856('../Data/Similarity/TR9856.csv')\n",
    "\n",
    "datasets = {\n",
    "    \"mturk\" : mturk,\n",
    "    \"men\" : men,\n",
    "    \"ws353\" : ws353,\n",
    "    \"rg65\" : rg65,\n",
    "    \"rw\" : rw,\n",
    "    \"simlex\" : simlex,\n",
    "    \"tr9856\" : tr9856\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(embedding):\n",
    "    results_df = pd.DataFrame(columns=[\"Dataset\", \"Spearman Correlation value\"])\n",
    "    \n",
    "    for key, value in datasets.items():\n",
    "        corr_val = evaluate_similarity(embedding, value['X'], value['y'])\n",
    "        results_df.loc[len(results_df)] = [key, corr_val]\n",
    "        \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 24 words. Will replace them with mean vector\n",
      "Missing 260 words. Will replace them with mean vector\n",
      "Missing 12079 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Spearman Correlation value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk</td>\n",
       "      <td>0.633182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>men</td>\n",
       "      <td>0.737465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ws353</td>\n",
       "      <td>0.543524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rg65</td>\n",
       "      <td>0.769525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rw</td>\n",
       "      <td>0.367045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simlex</td>\n",
       "      <td>0.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr9856</td>\n",
       "      <td>0.099480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Spearman Correlation value\n",
       "0   mturk                    0.633182\n",
       "1     men                    0.737465\n",
       "2   ws353                    0.543524\n",
       "3    rg65                    0.769525\n",
       "4      rw                    0.367045\n",
       "5  simlex                    0.370500\n",
       "6  tr9856                    0.099480"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GloVe\n",
    "compute_similarity(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 2 words. Will replace them with mean vector\n",
      "Missing 68 words. Will replace them with mean vector\n",
      "Missing 12191 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Spearman Correlation value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk</td>\n",
       "      <td>0.702289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>men</td>\n",
       "      <td>0.790633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ws353</td>\n",
       "      <td>0.733276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rg65</td>\n",
       "      <td>0.846259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rw</td>\n",
       "      <td>0.513497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simlex</td>\n",
       "      <td>0.449965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr9856</td>\n",
       "      <td>0.164246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Spearman Correlation value\n",
       "0   mturk                    0.702289\n",
       "1     men                    0.790633\n",
       "2   ws353                    0.733276\n",
       "3    rg65                    0.846259\n",
       "4      rw                    0.513497\n",
       "5  simlex                    0.449965\n",
       "6  tr9856                    0.164246"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fast Text\n",
    "compute_similarity(fast_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 1 words. Will replace them with mean vector\n",
      "Missing 24 words. Will replace them with mean vector\n",
      "Missing 288 words. Will replace them with mean vector\n",
      "Missing 1 words. Will replace them with mean vector\n",
      "Missing 12087 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Spearman Correlation value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk</td>\n",
       "      <td>0.648025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>men</td>\n",
       "      <td>0.765485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ws353</td>\n",
       "      <td>0.638120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rg65</td>\n",
       "      <td>0.793260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rw</td>\n",
       "      <td>0.446721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simlex</td>\n",
       "      <td>0.362670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr9856</td>\n",
       "      <td>0.131299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Spearman Correlation value\n",
       "0   mturk                    0.648025\n",
       "1     men                    0.765485\n",
       "2   ws353                    0.638120\n",
       "3    rg65                    0.793260\n",
       "4      rw                    0.446721\n",
       "5  simlex                    0.362670\n",
       "6  tr9856                    0.131299"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lex Vec\n",
    "compute_similarity(lex_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 24 words. Will replace them with mean vector\n",
      "Missing 204 words. Will replace them with mean vector\n",
      "Missing 12142 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Spearman Correlation value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk</td>\n",
       "      <td>0.718810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>men</td>\n",
       "      <td>0.866130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ws353</td>\n",
       "      <td>0.768220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rg65</td>\n",
       "      <td>0.924829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rw</td>\n",
       "      <td>0.568671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simlex</td>\n",
       "      <td>0.626787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr9856</td>\n",
       "      <td>0.132052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Spearman Correlation value\n",
       "0   mturk                    0.718810\n",
       "1     men                    0.866130\n",
       "2   ws353                    0.768220\n",
       "3    rg65                    0.924829\n",
       "4      rw                    0.568671\n",
       "5  simlex                    0.626787\n",
       "6  tr9856                    0.132052"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ConceptNet Number batch\n",
    "compute_similarity(concept_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 12 words. Will replace them with mean vector\n",
      "Missing 55 words. Will replace them with mean vector\n",
      "Missing 216 words. Will replace them with mean vector\n",
      "Missing 12282 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Spearman Correlation value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mturk</td>\n",
       "      <td>0.680567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>men</td>\n",
       "      <td>0.758586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ws353</td>\n",
       "      <td>0.700017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rg65</td>\n",
       "      <td>0.760783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rw</td>\n",
       "      <td>0.497720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simlex</td>\n",
       "      <td>0.441966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr9856</td>\n",
       "      <td>0.181381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Spearman Correlation value\n",
       "0   mturk                    0.680567\n",
       "1     men                    0.758586\n",
       "2   ws353                    0.700017\n",
       "3    rg65                    0.760783\n",
       "4      rw                    0.497720\n",
       "5  simlex                    0.441966\n",
       "6  tr9856                    0.181381"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Google News\n",
    "compute_similarity(google_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Analogy\n",
    "\n",
    "Experiments (In terms of overall accuracy on all categories):<br/>\n",
    "Per parameter results are presented as tuples of (Overall accuracy %, number of corrects, total number of words) <br/>\n",
    "Results are provided with add rather than mul <br/>\n",
    "<br/>\n",
    "\n",
    "<b>GloVe:</b> <br/> \n",
    "<i>(Evaluation time: 15 mins on average)</i> <br/>\n",
    "* 300d : 65%, 12723, 19544\n",
    "* 200d : 60.8%, 11894, 19544\n",
    "* 100d : 49.7% , 9730, 19544\n",
    "* 50d  : 20.4%, 3997, 19544 \n",
    "\n",
    "<b>FastText:</b> <br/>\n",
    "<i>(Evaluation time: 20 mins)</i> <br/>\n",
    "* 300d : 9.2%, 1815, 19544\n",
    "\n",
    "<b>LexVec </b>\n",
    "* 300d : 60.4%, 11805, 19544\n",
    "\n",
    "<b> ConceptNet </b>\n",
    "* 300d : 31.9%, 6242, 19544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_analogy(embedding, dataset):\n",
    "    return evaluate_analogy(embedding, dataset['X'], dataset['y'], category=dataset['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_analogy = fetch_google_analogy('../Data/Analogy/EN-GOOGLE.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.650993</td>\n",
       "      <td>12723</td>\n",
       "      <td>19544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>0.706456</td>\n",
       "      <td>941</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>0.528409</td>\n",
       "      <td>558</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0.189376</td>\n",
       "      <td>164</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>0.912246</td>\n",
       "      <td>4127</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>0.628342</td>\n",
       "      <td>705</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>0.602351</td>\n",
       "      <td>1486</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>0.804805</td>\n",
       "      <td>1072</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>0.498851</td>\n",
       "      <td>434</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>0.209360</td>\n",
       "      <td>170</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>0.412821</td>\n",
       "      <td>644</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>0.948617</td>\n",
       "      <td>480</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>0.918699</td>\n",
       "      <td>1469</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>0.090726</td>\n",
       "      <td>90</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.756917</td>\n",
       "      <td>383</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  correct  count\n",
       "all                          0.650993    12723  19544\n",
       "gram8-plural                 0.706456      941   1332\n",
       "gram5-present-participle     0.528409      558   1056\n",
       "currency                     0.189376      164    866\n",
       "capital-world                0.912246     4127   4524\n",
       "gram4-superlative            0.628342      705   1122\n",
       "city-in-state                0.602351     1486   2467\n",
       "gram3-comparative            0.804805     1072   1332\n",
       "gram9-plural-verbs           0.498851      434    870\n",
       "gram2-opposite               0.209360      170    812\n",
       "gram7-past-tense             0.412821      644   1560\n",
       "capital-common-countries     0.948617      480    506\n",
       "gram6-nationality-adjective  0.918699     1469   1599\n",
       "gram1-adjective-to-adverb    0.090726       90    992\n",
       "family                       0.756917      383    506"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GloVe\n",
    "results = compute_analogy(glove, google_analogy)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 4667 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.092867</td>\n",
       "      <td>1815</td>\n",
       "      <td>19544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>0.171402</td>\n",
       "      <td>181</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>0.291444</td>\n",
       "      <td>327</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>592</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>0.150575</td>\n",
       "      <td>131</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>0.113300</td>\n",
       "      <td>92</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>0.293590</td>\n",
       "      <td>458</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>0.001251</td>\n",
       "      <td>2</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>32</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  correct  count\n",
       "all                          0.092867     1815  19544\n",
       "gram8-plural                 0.000000        0   1332\n",
       "gram5-present-participle     0.171402      181   1056\n",
       "currency                     0.000000        0    866\n",
       "capital-world                0.000000        0   4524\n",
       "gram4-superlative            0.291444      327   1122\n",
       "city-in-state                0.000000        0   2467\n",
       "gram3-comparative            0.444444      592   1332\n",
       "gram9-plural-verbs           0.150575      131    870\n",
       "gram2-opposite               0.113300       92    812\n",
       "gram7-past-tense             0.293590      458   1560\n",
       "capital-common-countries     0.000000        0    506\n",
       "gram6-nationality-adjective  0.001251        2   1599\n",
       "gram1-adjective-to-adverb    0.032258       32    992\n",
       "family                       0.000000        0    506"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fast Text\n",
    "results = compute_analogy(fast_text, google_analogy)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.604022</td>\n",
       "      <td>11805</td>\n",
       "      <td>19544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>0.560811</td>\n",
       "      <td>747</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>0.366477</td>\n",
       "      <td>387</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0.271363</td>\n",
       "      <td>235</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>0.862069</td>\n",
       "      <td>3900</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>0.491979</td>\n",
       "      <td>552</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>0.630726</td>\n",
       "      <td>1556</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>0.755255</td>\n",
       "      <td>1006</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>0.391954</td>\n",
       "      <td>341</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>0.200739</td>\n",
       "      <td>163</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>0.372436</td>\n",
       "      <td>581</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>0.800395</td>\n",
       "      <td>405</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>0.897436</td>\n",
       "      <td>1435</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>0.060484</td>\n",
       "      <td>60</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>437</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  correct  count\n",
       "all                          0.604022    11805  19544\n",
       "gram8-plural                 0.560811      747   1332\n",
       "gram5-present-participle     0.366477      387   1056\n",
       "currency                     0.271363      235    866\n",
       "capital-world                0.862069     3900   4524\n",
       "gram4-superlative            0.491979      552   1122\n",
       "city-in-state                0.630726     1556   2467\n",
       "gram3-comparative            0.755255     1006   1332\n",
       "gram9-plural-verbs           0.391954      341    870\n",
       "gram2-opposite               0.200739      163    812\n",
       "gram7-past-tense             0.372436      581   1560\n",
       "capital-common-countries     0.800395      405    506\n",
       "gram6-nationality-adjective  0.897436     1435   1599\n",
       "gram1-adjective-to-adverb    0.060484       60    992\n",
       "family                       0.863636      437    506"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lex Vec\n",
    "results = compute_analogy(lex_vec, google_analogy)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.319382</td>\n",
       "      <td>6242</td>\n",
       "      <td>19544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>0.162162</td>\n",
       "      <td>216</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>0.242424</td>\n",
       "      <td>256</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0.128176</td>\n",
       "      <td>111</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>0.388815</td>\n",
       "      <td>1759</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>0.680036</td>\n",
       "      <td>763</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>0.158087</td>\n",
       "      <td>390</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>0.554054</td>\n",
       "      <td>738</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>0.243678</td>\n",
       "      <td>212</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>0.096059</td>\n",
       "      <td>78</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>0.291026</td>\n",
       "      <td>454</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>0.262846</td>\n",
       "      <td>133</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>0.537211</td>\n",
       "      <td>859</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>0.116935</td>\n",
       "      <td>116</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.310277</td>\n",
       "      <td>157</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  correct  count\n",
       "all                          0.319382     6242  19544\n",
       "gram8-plural                 0.162162      216   1332\n",
       "gram5-present-participle     0.242424      256   1056\n",
       "currency                     0.128176      111    866\n",
       "capital-world                0.388815     1759   4524\n",
       "gram4-superlative            0.680036      763   1122\n",
       "city-in-state                0.158087      390   2467\n",
       "gram3-comparative            0.554054      738   1332\n",
       "gram9-plural-verbs           0.243678      212    870\n",
       "gram2-opposite               0.096059       78    812\n",
       "gram7-past-tense             0.291026      454   1560\n",
       "capital-common-countries     0.262846      133    506\n",
       "gram6-nationality-adjective  0.537211      859   1599\n",
       "gram1-adjective-to-adverb    0.116935      116    992\n",
       "family                       0.310277      157    506"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ConceptNet Number batch\n",
    "results = compute_analogy(concept_net, google_analogy)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 9402 words. Will replace them with mean vector\n",
      "../word-embeddings-benchmark\\web\\analogy.py:105: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A, B, C = np.vstack(w.get(word, mean_vector) for word in X_b[:, 0]), \\\n",
      "../word-embeddings-benchmark\\web\\analogy.py:106: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 1]), \\\n",
      "../word-embeddings-benchmark\\web\\analogy.py:107: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.012331</td>\n",
       "      <td>241</td>\n",
       "      <td>19544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>0.049550</td>\n",
       "      <td>66</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>0.024621</td>\n",
       "      <td>26</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0.006928</td>\n",
       "      <td>6</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>6</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>0.001783</td>\n",
       "      <td>2</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>0.021484</td>\n",
       "      <td>53</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>0.008258</td>\n",
       "      <td>11</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>0.045977</td>\n",
       "      <td>40</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>0.017308</td>\n",
       "      <td>27</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>0.001976</td>\n",
       "      <td>1</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>0.001251</td>\n",
       "      <td>2</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.001976</td>\n",
       "      <td>1</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  correct  count\n",
       "all                          0.012331      241  19544\n",
       "gram8-plural                 0.049550       66   1332\n",
       "gram5-present-participle     0.024621       26   1056\n",
       "currency                     0.006928        6    866\n",
       "capital-world                0.001326        6   4524\n",
       "gram4-superlative            0.001783        2   1122\n",
       "city-in-state                0.021484       53   2467\n",
       "gram3-comparative            0.008258       11   1332\n",
       "gram9-plural-verbs           0.045977       40    870\n",
       "gram2-opposite               0.000000        0    812\n",
       "gram7-past-tense             0.017308       27   1560\n",
       "capital-common-countries     0.001976        1    506\n",
       "gram6-nationality-adjective  0.001251        2   1599\n",
       "gram1-adjective-to-adverb    0.000000        0    992\n",
       "family                       0.001976        1    506"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Google News\n",
    "results = compute_analogy(google_news, google_analogy)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.380833</td>\n",
       "      <td>7443</td>\n",
       "      <td>19544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>0.491742</td>\n",
       "      <td>655</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>0.263258</td>\n",
       "      <td>278</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0.027714</td>\n",
       "      <td>24</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>0.478338</td>\n",
       "      <td>2164</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>0.395722</td>\n",
       "      <td>444</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>0.475882</td>\n",
       "      <td>1174</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>0.530030</td>\n",
       "      <td>706</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>0.520690</td>\n",
       "      <td>453</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>0.221675</td>\n",
       "      <td>180</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>0.260256</td>\n",
       "      <td>406</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>0.154150</td>\n",
       "      <td>78</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>0.411507</td>\n",
       "      <td>658</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>0.036290</td>\n",
       "      <td>36</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.369565</td>\n",
       "      <td>187</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  correct  count\n",
       "all                          0.380833     7443  19544\n",
       "gram8-plural                 0.491742      655   1332\n",
       "gram5-present-participle     0.263258      278   1056\n",
       "currency                     0.027714       24    866\n",
       "capital-world                0.478338     2164   4524\n",
       "gram4-superlative            0.395722      444   1122\n",
       "city-in-state                0.475882     1174   2467\n",
       "gram3-comparative            0.530030      706   1332\n",
       "gram9-plural-verbs           0.520690      453    870\n",
       "gram2-opposite               0.221675      180    812\n",
       "gram7-past-tense             0.260256      406   1560\n",
       "capital-common-countries     0.154150       78    506\n",
       "gram6-nationality-adjective  0.411507      658   1599\n",
       "gram1-adjective-to-adverb    0.036290       36    992\n",
       "family                       0.369565      187    506"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PDC\n",
    "results = compute_analogy(pdc, google_analogy)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../word-embeddings-benchmark\\web\\analogy.py:105: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A, B, C = np.vstack(w.get(word, mean_vector) for word in X_b[:, 0]), \\\n",
      "../word-embeddings-benchmark\\web\\analogy.py:106: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 1]), \\\n",
      "../word-embeddings-benchmark\\web\\analogy.py:107: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.288682</td>\n",
       "      <td>5642</td>\n",
       "      <td>19544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>0.205706</td>\n",
       "      <td>274</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>0.155303</td>\n",
       "      <td>164</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0.124711</td>\n",
       "      <td>108</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>0.403846</td>\n",
       "      <td>1827</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>0.205882</td>\n",
       "      <td>231</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>0.407377</td>\n",
       "      <td>1005</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>0.292793</td>\n",
       "      <td>390</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>0.414943</td>\n",
       "      <td>361</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>0.158867</td>\n",
       "      <td>129</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>0.210256</td>\n",
       "      <td>328</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>0.122530</td>\n",
       "      <td>62</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>0.342714</td>\n",
       "      <td>548</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>0.008065</td>\n",
       "      <td>8</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.409091</td>\n",
       "      <td>207</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  correct  count\n",
       "all                          0.288682     5642  19544\n",
       "gram8-plural                 0.205706      274   1332\n",
       "gram5-present-participle     0.155303      164   1056\n",
       "currency                     0.124711      108    866\n",
       "capital-world                0.403846     1827   4524\n",
       "gram4-superlative            0.205882      231   1122\n",
       "city-in-state                0.407377     1005   2467\n",
       "gram3-comparative            0.292793      390   1332\n",
       "gram9-plural-verbs           0.414943      361    870\n",
       "gram2-opposite               0.158867      129    812\n",
       "gram7-past-tense             0.210256      328   1560\n",
       "capital-common-countries     0.122530       62    506\n",
       "gram6-nationality-adjective  0.342714      548   1599\n",
       "gram1-adjective-to-adverb    0.008065        8    992\n",
       "family                       0.409091      207    506"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HDC\n",
    "results = compute_analogy(hdc, google_analogy)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr = fetch_msr_analogy('../Data/Analogy/EN-MSR.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 164 words. Will replace them with mean vector\n",
      "../word-embeddings-benchmark\\web\\analogy.py:105: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A, B, C = np.vstack(w.get(word, mean_vector) for word in X_b[:, 0]), \\\n",
      "../word-embeddings-benchmark\\web\\analogy.py:106: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 1]), \\\n",
      "../word-embeddings-benchmark\\web\\analogy.py:107: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.514125</td>\n",
       "      <td>4113</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jj</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>175</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjs</th>\n",
       "      <td>0.478000</td>\n",
       "      <td>239</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnpos_nn</th>\n",
       "      <td>0.456000</td>\n",
       "      <td>228</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jjr</th>\n",
       "      <td>0.574000</td>\n",
       "      <td>287</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjr</th>\n",
       "      <td>0.596000</td>\n",
       "      <td>298</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nns_nn</th>\n",
       "      <td>0.518000</td>\n",
       "      <td>259</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbz</th>\n",
       "      <td>0.656000</td>\n",
       "      <td>328</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vb</th>\n",
       "      <td>0.780000</td>\n",
       "      <td>390</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nns</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>340</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nnpos</th>\n",
       "      <td>0.332000</td>\n",
       "      <td>166</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbd</th>\n",
       "      <td>0.396000</td>\n",
       "      <td>198</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vbd</th>\n",
       "      <td>0.358000</td>\n",
       "      <td>179</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vbz</th>\n",
       "      <td>0.446000</td>\n",
       "      <td>223</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jjs</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jj</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>220</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vb</th>\n",
       "      <td>0.666000</td>\n",
       "      <td>333</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  correct  count\n",
       "all       0.514125     4113   8000\n",
       "jjs_jj    0.350000      175    500\n",
       "jj_jjs    0.478000      239    500\n",
       "nnpos_nn  0.456000      228    500\n",
       "jjs_jjr   0.574000      287    500\n",
       "jj_jjr    0.596000      298    500\n",
       "nns_nn    0.518000      259    500\n",
       "vb_vbz    0.656000      328    500\n",
       "vbz_vb    0.780000      390    500\n",
       "nn_nns    0.680000      340    500\n",
       "nn_nnpos  0.332000      166    500\n",
       "vb_vbd    0.396000      198    500\n",
       "vbz_vbd   0.358000      179    500\n",
       "vbd_vbz   0.446000      223    500\n",
       "jjr_jjs   0.500000      250    500\n",
       "jjr_jj    0.440000      220    500\n",
       "vbd_vb    0.666000      333    500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GloVe\n",
    "results = compute_analogy(glove, msr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.1785</td>\n",
       "      <td>1428</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jj</th>\n",
       "      <td>0.0900</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjs</th>\n",
       "      <td>0.1860</td>\n",
       "      <td>93</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnpos_nn</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jjr</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>125</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjr</th>\n",
       "      <td>0.3120</td>\n",
       "      <td>156</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nns_nn</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbz</th>\n",
       "      <td>0.2160</td>\n",
       "      <td>108</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vb</th>\n",
       "      <td>0.4180</td>\n",
       "      <td>209</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nns</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nnpos</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbd</th>\n",
       "      <td>0.2560</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vbd</th>\n",
       "      <td>0.2440</td>\n",
       "      <td>122</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vbz</th>\n",
       "      <td>0.1620</td>\n",
       "      <td>81</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jjs</th>\n",
       "      <td>0.1680</td>\n",
       "      <td>84</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jj</th>\n",
       "      <td>0.1500</td>\n",
       "      <td>75</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vb</th>\n",
       "      <td>0.4040</td>\n",
       "      <td>202</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  correct  count\n",
       "all         0.1785     1428   8000\n",
       "jjs_jj      0.0900       45    500\n",
       "jj_jjs      0.1860       93    500\n",
       "nnpos_nn    0.0000        0    500\n",
       "jjs_jjr     0.2500      125    500\n",
       "jj_jjr      0.3120      156    500\n",
       "nns_nn      0.0000        0    500\n",
       "vb_vbz      0.2160      108    500\n",
       "vbz_vb      0.4180      209    500\n",
       "nn_nns      0.0000        0    500\n",
       "nn_nnpos    0.0000        0    500\n",
       "vb_vbd      0.2560      128    500\n",
       "vbz_vbd     0.2440      122    500\n",
       "vbd_vbz     0.1620       81    500\n",
       "jjr_jjs     0.1680       84    500\n",
       "jjr_jj      0.1500       75    500\n",
       "vbd_vb      0.4040      202    500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fast Text\n",
    "results = compute_analogy(fast_text, msr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 131 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.37075</td>\n",
       "      <td>2966</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jj</th>\n",
       "      <td>0.22200</td>\n",
       "      <td>111</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjs</th>\n",
       "      <td>0.45000</td>\n",
       "      <td>225</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnpos_nn</th>\n",
       "      <td>0.27600</td>\n",
       "      <td>138</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jjr</th>\n",
       "      <td>0.47200</td>\n",
       "      <td>236</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjr</th>\n",
       "      <td>0.54000</td>\n",
       "      <td>270</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nns_nn</th>\n",
       "      <td>0.32200</td>\n",
       "      <td>161</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbz</th>\n",
       "      <td>0.40800</td>\n",
       "      <td>204</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vb</th>\n",
       "      <td>0.50400</td>\n",
       "      <td>252</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nns</th>\n",
       "      <td>0.51000</td>\n",
       "      <td>255</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nnpos</th>\n",
       "      <td>0.29000</td>\n",
       "      <td>145</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbd</th>\n",
       "      <td>0.27800</td>\n",
       "      <td>139</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vbd</th>\n",
       "      <td>0.23000</td>\n",
       "      <td>115</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vbz</th>\n",
       "      <td>0.27800</td>\n",
       "      <td>139</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jjs</th>\n",
       "      <td>0.41200</td>\n",
       "      <td>206</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jj</th>\n",
       "      <td>0.35200</td>\n",
       "      <td>176</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vb</th>\n",
       "      <td>0.38800</td>\n",
       "      <td>194</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  correct  count\n",
       "all        0.37075     2966   8000\n",
       "jjs_jj     0.22200      111    500\n",
       "jj_jjs     0.45000      225    500\n",
       "nnpos_nn   0.27600      138    500\n",
       "jjs_jjr    0.47200      236    500\n",
       "jj_jjr     0.54000      270    500\n",
       "nns_nn     0.32200      161    500\n",
       "vb_vbz     0.40800      204    500\n",
       "vbz_vb     0.50400      252    500\n",
       "nn_nns     0.51000      255    500\n",
       "nn_nnpos   0.29000      145    500\n",
       "vb_vbd     0.27800      139    500\n",
       "vbz_vbd    0.23000      115    500\n",
       "vbd_vbz    0.27800      139    500\n",
       "jjr_jjs    0.41200      206    500\n",
       "jjr_jj     0.35200      176    500\n",
       "vbd_vb     0.38800      194    500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lex Vec\n",
    "results = compute_analogy(lex_vec, msr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 302 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.4395</td>\n",
       "      <td>3516</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jj</th>\n",
       "      <td>0.6020</td>\n",
       "      <td>301</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjs</th>\n",
       "      <td>0.5220</td>\n",
       "      <td>261</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnpos_nn</th>\n",
       "      <td>0.3360</td>\n",
       "      <td>168</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jjr</th>\n",
       "      <td>0.7900</td>\n",
       "      <td>395</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjr</th>\n",
       "      <td>0.4300</td>\n",
       "      <td>215</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nns_nn</th>\n",
       "      <td>0.3900</td>\n",
       "      <td>195</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbz</th>\n",
       "      <td>0.3060</td>\n",
       "      <td>153</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vb</th>\n",
       "      <td>0.7040</td>\n",
       "      <td>352</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nns</th>\n",
       "      <td>0.0480</td>\n",
       "      <td>24</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nnpos</th>\n",
       "      <td>0.0640</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbd</th>\n",
       "      <td>0.2680</td>\n",
       "      <td>134</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vbd</th>\n",
       "      <td>0.4580</td>\n",
       "      <td>229</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vbz</th>\n",
       "      <td>0.4020</td>\n",
       "      <td>201</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jjs</th>\n",
       "      <td>0.7900</td>\n",
       "      <td>395</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jj</th>\n",
       "      <td>0.4960</td>\n",
       "      <td>248</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vb</th>\n",
       "      <td>0.4260</td>\n",
       "      <td>213</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  correct  count\n",
       "all         0.4395     3516   8000\n",
       "jjs_jj      0.6020      301    500\n",
       "jj_jjs      0.5220      261    500\n",
       "nnpos_nn    0.3360      168    500\n",
       "jjs_jjr     0.7900      395    500\n",
       "jj_jjr      0.4300      215    500\n",
       "nns_nn      0.3900      195    500\n",
       "vb_vbz      0.3060      153    500\n",
       "vbz_vb      0.7040      352    500\n",
       "nn_nns      0.0480       24    500\n",
       "nn_nnpos    0.0640       32    500\n",
       "vb_vbd      0.2680      134    500\n",
       "vbz_vbd     0.4580      229    500\n",
       "vbd_vbz     0.4020      201    500\n",
       "jjr_jjs     0.7900      395    500\n",
       "jjr_jj      0.4960      248    500\n",
       "vbd_vb      0.4260      213    500"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concept Net\n",
    "results = compute_analogy(concept_net, msr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.006625</td>\n",
       "      <td>53</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jj</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjs</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnpos_nn</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jjr</th>\n",
       "      <td>0.012000</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjr</th>\n",
       "      <td>0.022000</td>\n",
       "      <td>11</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nns_nn</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbz</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vb</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nns</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nnpos</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbd</th>\n",
       "      <td>0.012000</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vbd</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vbz</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jjs</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jj</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vb</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  correct  count\n",
       "all       0.006625       53   8000\n",
       "jjs_jj    0.004000        2    500\n",
       "jj_jjs    0.010000        5    500\n",
       "nnpos_nn  0.004000        2    500\n",
       "jjs_jjr   0.012000        6    500\n",
       "jj_jjr    0.022000       11    500\n",
       "nns_nn    0.008000        4    500\n",
       "vb_vbz    0.006000        3    500\n",
       "vbz_vb    0.000000        0    500\n",
       "nn_nns    0.004000        2    500\n",
       "nn_nnpos  0.000000        0    500\n",
       "vb_vbd    0.012000        6    500\n",
       "vbz_vbd   0.004000        2    500\n",
       "vbd_vbz   0.010000        5    500\n",
       "jjr_jjs   0.006000        3    500\n",
       "jjr_jj    0.004000        2    500\n",
       "vbd_vb    0.000000        0    500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Google News\n",
    "results = compute_analogy(google_news, msr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 241 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.26525</td>\n",
       "      <td>2122</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jj</th>\n",
       "      <td>0.06800</td>\n",
       "      <td>34</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjs</th>\n",
       "      <td>0.26400</td>\n",
       "      <td>132</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnpos_nn</th>\n",
       "      <td>0.18000</td>\n",
       "      <td>90</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jjr</th>\n",
       "      <td>0.25400</td>\n",
       "      <td>127</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjr</th>\n",
       "      <td>0.28000</td>\n",
       "      <td>140</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nns_nn</th>\n",
       "      <td>0.19600</td>\n",
       "      <td>98</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbz</th>\n",
       "      <td>0.65200</td>\n",
       "      <td>326</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vb</th>\n",
       "      <td>0.39000</td>\n",
       "      <td>195</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nns</th>\n",
       "      <td>0.29800</td>\n",
       "      <td>149</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nnpos</th>\n",
       "      <td>0.18600</td>\n",
       "      <td>93</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbd</th>\n",
       "      <td>0.16800</td>\n",
       "      <td>84</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vbd</th>\n",
       "      <td>0.16800</td>\n",
       "      <td>84</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vbz</th>\n",
       "      <td>0.52800</td>\n",
       "      <td>264</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jjs</th>\n",
       "      <td>0.25800</td>\n",
       "      <td>129</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jj</th>\n",
       "      <td>0.08200</td>\n",
       "      <td>41</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vb</th>\n",
       "      <td>0.27200</td>\n",
       "      <td>136</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  correct  count\n",
       "all        0.26525     2122   8000\n",
       "jjs_jj     0.06800       34    500\n",
       "jj_jjs     0.26400      132    500\n",
       "nnpos_nn   0.18000       90    500\n",
       "jjs_jjr    0.25400      127    500\n",
       "jj_jjr     0.28000      140    500\n",
       "nns_nn     0.19600       98    500\n",
       "vb_vbz     0.65200      326    500\n",
       "vbz_vb     0.39000      195    500\n",
       "nn_nns     0.29800      149    500\n",
       "nn_nnpos   0.18600       93    500\n",
       "vb_vbd     0.16800       84    500\n",
       "vbz_vbd    0.16800       84    500\n",
       "vbd_vbz    0.52800      264    500\n",
       "jjr_jjs    0.25800      129    500\n",
       "jjr_jj     0.08200       41    500\n",
       "vbd_vb     0.27200      136    500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PDC\n",
    "results = compute_analogy(pdc, msr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 241 words. Will replace them with mean vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.1395</td>\n",
       "      <td>1116</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jj</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>13</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjs</th>\n",
       "      <td>0.2220</td>\n",
       "      <td>111</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnpos_nn</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjs_jjr</th>\n",
       "      <td>0.1400</td>\n",
       "      <td>70</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj_jjr</th>\n",
       "      <td>0.1920</td>\n",
       "      <td>96</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nns_nn</th>\n",
       "      <td>0.0920</td>\n",
       "      <td>46</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbz</th>\n",
       "      <td>0.3660</td>\n",
       "      <td>183</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vb</th>\n",
       "      <td>0.1440</td>\n",
       "      <td>72</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nns</th>\n",
       "      <td>0.1460</td>\n",
       "      <td>73</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_nnpos</th>\n",
       "      <td>0.1140</td>\n",
       "      <td>57</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vb_vbd</th>\n",
       "      <td>0.0740</td>\n",
       "      <td>37</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbz_vbd</th>\n",
       "      <td>0.0440</td>\n",
       "      <td>22</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vbz</th>\n",
       "      <td>0.1940</td>\n",
       "      <td>97</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jjs</th>\n",
       "      <td>0.2320</td>\n",
       "      <td>116</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jjr_jj</th>\n",
       "      <td>0.0460</td>\n",
       "      <td>23</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vbd_vb</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  correct  count\n",
       "all         0.1395     1116   8000\n",
       "jjs_jj      0.0260       13    500\n",
       "jj_jjs      0.2220      111    500\n",
       "nnpos_nn    0.1000       50    500\n",
       "jjs_jjr     0.1400       70    500\n",
       "jj_jjr      0.1920       96    500\n",
       "nns_nn      0.0920       46    500\n",
       "vb_vbz      0.3660      183    500\n",
       "vbz_vb      0.1440       72    500\n",
       "nn_nns      0.1460       73    500\n",
       "nn_nnpos    0.1140       57    500\n",
       "vb_vbd      0.0740       37    500\n",
       "vbz_vbd     0.0440       22    500\n",
       "vbd_vbz     0.1940       97    500\n",
       "jjr_jjs     0.2320      116    500\n",
       "jjr_jj      0.0460       23    500\n",
       "vbd_vb      0.1000       50    500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HDC\n",
    "results = compute_analogy(hdc, msr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Rep\n",
    "word_rep = fetch_wordrep('../Data/Analogy/WordRep/', 0.1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4458"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_rep['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../word-embeddings-benchmark\\web\\analogy.py:101: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if id_batch % np.floor(len(X) / (10. * self.batch_size)) == 0:\n",
      "../word-embeddings-benchmark\\web\\analogy.py:105: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A, B, C = np.vstack(w.get(word, mean_vector) for word in X_b[:, 0]), \\\n",
      "../word-embeddings-benchmark\\web\\analogy.py:106: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 1]), \\\n",
      "../word-embeddings-benchmark\\web\\analogy.py:107: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  np.vstack(w.get(word, mean_vector) for word in X_b[:, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Projects\\NLP_Training\\word-embeddings-benchmark\\web\\utils.py\u001b[0m in \u001b[0;36mbatched\u001b[1;34m(iterable, size)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mbatchiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msourceiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-561e1fe33abe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#GloVe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_on_WordRep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/Analogy/WordRep/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Projects\\NLP_Training\\word-embeddings-benchmark\\web\\evaluate.py\u001b[0m in \u001b[0;36mevaluate_on_WordRep\u001b[1;34m(folder_path, subsample, rng, w, max_pairs, solver_kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;31m# Run solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleAnalogySolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msolver_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[0mcorrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mcount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Projects\\NLP_Training\\word-embeddings-benchmark\\web\\analogy.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# Batch due to memory constaints (in dot operation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mid_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m             \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mX_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "#GloVe\n",
    "results = evaluate_on_WordRep('../Data/Analogy/WordRep/', 0.1, 10, glove)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fast Text\n",
    "results = evaluate_on_WordRep('../Data/Analogy/WordRep/', 0.4, 10, fast_text)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lex Vec\n",
    "results = evaluate_on_WordRep('../Data/Analogy/WordRep/', 0.4, 10, lex_vec)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concept Net\n",
    "results = evaluate_on_WordRep('../Data/Analogy/WordRep/', 0.4, 10, concept_new)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google News\n",
    "results = evaluate_on_WordRep('../Data/Analogy/WordRep/', 0.4, 10, google_news)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDC\n",
    "results = evaluate_on_WordRep('../Data/Analogy/WordRep/', 0.4, 10, pdc)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HDC\n",
    "results = evaluate_on_WordRep('../Data/Analogy/WordRep/', 0.4, 10, hdc)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConceptNet\n",
    "results = evaluate_analogy(concept_net, google_analogy['X'], google_analogy['y'], category=google_analogy['category'])\n",
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of similarity datasets to be evaluated:\n",
    "MTurk, MEN, WS353, Rubenstein and Goodenough, Rare Words, SimLex999, TR9856 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just downloading the files to compare and ensure I have the right datasets\n",
    "\n",
    "\n",
    "# dataset = fetch_MTurk()  #Downloaded. Yet to be understood\n",
    "# dataset = fetch_MEN()   #Not Downloaded\n",
    "# dataset = fetch_WS353(\"relatedness\") #Downloaded. Difference between relatedness and attributional\n",
    "# dataset = fetch_RG65() #Downloaded : Evaluate\n",
    "# dataset = fetch_RW() #Downloaded : Downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr = fetch_wordrep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
